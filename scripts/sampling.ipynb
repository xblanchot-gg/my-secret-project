{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992443e-2a9a-4a05-b401-ec6162eb6627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import train_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e8ad6-8f32-4b95-992b-22c40e1febd1",
   "metadata": {},
   "source": [
    "train_regression.py --all-metrics -m llama3:8b -d mixed_qa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbebe2-717f-4b12-b82f-5fcc18f5fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['llama3:8b','llama3.2:1b','gpt-4.1-mini']\n",
    "datasets = ['truthful_qa', 'mixed_qa', 'med_qa']\n",
    "\n",
    "key=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "840c199c-4036-470d-adf1-b33fcfc717cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- STARTING FOR llama3:8b-truthful_qa ----------\n",
      "Making output directory at saved_models/lookups/llama3:8b-truthful_qa\n",
      "Model rated itself with the following unique values [ 5.  4.  3.  1.  2. nan]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/llama3:8b-truthful_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/llama3:8b-truthful_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/llama3:8b-truthful_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/llama3:8b-truthful_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/llama3:8b-truthful_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/llama3:8b-truthful_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/llama3:8b-truthful_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/llama3:8b-truthful_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/llama3:8b-truthful_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR llama3:8b-mixed_qa ----------\n",
      "Making output directory at saved_models/lookups/llama3:8b-mixed_qa\n",
      "Model rated itself with the following unique values [ 5.  4.  3.  1.  2. nan]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/llama3:8b-mixed_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/llama3:8b-mixed_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/llama3:8b-mixed_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/llama3:8b-mixed_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/llama3:8b-mixed_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/llama3:8b-mixed_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/llama3:8b-mixed_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/llama3:8b-mixed_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/llama3:8b-mixed_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR llama3:8b-med_qa ----------\n",
      "Making output directory at saved_models/lookups/llama3:8b-med_qa\n",
      "Model rated itself with the following unique values [5 4 3]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/llama3:8b-med_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/llama3:8b-med_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/llama3:8b-med_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/llama3:8b-med_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/llama3:8b-med_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/llama3:8b-med_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/llama3:8b-med_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/llama3:8b-med_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/llama3:8b-med_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR llama3.2:1b-truthful_qa ----------\n",
      "Making output directory at saved_models/lookups/llama3.2:1b-truthful_qa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/git/TrustBench/trustbench/train_regression.py:121: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  model_outs = pd.read_json(f\"./results/{model}-{dataset}/outputs_with_confidence.jsonl\",lines=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m10\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSTARTING FOR \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m10\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtrain_regression\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mall_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/d/git/TrustBench/trustbench/train_regression.py:121\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(model, dataset, all_metrics, metric, y_min, y_max)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMaking output directory at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    119\u001b[39m os.makedirs(out_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m model_outs = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./results/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/outputs_with_confidence.jsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel rated itself with the following unique values \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpd.unique(model_outs[\u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m(metric==\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m all_metrics==\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/trustBench/lib/python3.13/site-packages/pandas/io/json/_json.py:815\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/trustBench/lib/python3.13/site-packages/pandas/io/json/_json.py:1012\u001b[39m, in \u001b[36mJsonReader.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1010\u001b[39m         data = ensure_str(\u001b[38;5;28mself\u001b[39m.data)\n\u001b[32m   1011\u001b[39m         data_lines = data.split(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m         obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_combine_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lines\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1014\u001b[39m     obj = \u001b[38;5;28mself\u001b[39m._get_object_parser(\u001b[38;5;28mself\u001b[39m.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/trustBench/lib/python3.13/site-packages/pandas/io/json/_json.py:1040\u001b[39m, in \u001b[36mJsonReader._get_object_parser\u001b[39m\u001b[34m(self, json)\u001b[39m\n\u001b[32m   1038\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m     obj = \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mseries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/trustBench/lib/python3.13/site-packages/pandas/io/json/_json.py:1176\u001b[39m, in \u001b[36mParser.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1174\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   1175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1176\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/trustBench/lib/python3.13/site-packages/pandas/io/json/_json.py:1392\u001b[39m, in \u001b[36mFrameParser._parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1388\u001b[39m orient = \u001b[38;5;28mself\u001b[39m.orient\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m orient == \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1391\u001b[39m     \u001b[38;5;28mself\u001b[39m.obj = DataFrame(\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m         \u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1393\u001b[39m     )\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m orient == \u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1395\u001b[39m     decoded = {\n\u001b[32m   1396\u001b[39m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float=\u001b[38;5;28mself\u001b[39m.precise_float).items()\n\u001b[32m   1398\u001b[39m     }\n",
      "\u001b[31mValueError\u001b[39m: Expected object or value"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        print(\"-\"*10, f\"STARTING FOR {model}-{dataset}\",\"-\"*10)\n",
    "        train_regression.main(model=model,dataset=dataset,all_metrics=True)\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e637425-3b85-4d8f-85e4-73eae26622d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b235cf9c-3c12-422e-96a3-21270753cf80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e65572-3f84-4785-8dd9-ffcf6c180b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26918b75-a7ab-46f4-9560-6e35b3866ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OLLAMA = \"llama2:7b\"\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bf9f9e-8616-4cd6-b0e6-a2ff1d8d42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model: str = MODEL_OLLAMA\n",
    "temperature: float = 0.3\n",
    "top_p: float = 0.9\n",
    "max_tokens: int = 256\n",
    "seed: int = SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b2c4155-bcdc-4521-be97-79b8ab86b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= \"Trilochanapala, last king of the Kabul Shahi dynasty, ruled in the site of which modern country?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17f78519-6734-4c7a-bea3-c870f4fdff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request(\n",
    "    \"http://localhost:11434/api/generate\",\n",
    "    data=json.dumps({\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"seed\": seed,\n",
    "        \"stream\": False\n",
    "    }).encode(\"utf-8\"),\n",
    "    headers={\"Content-Type\": \"application/json\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14241513-8bf6-4c3b-a7cf-b1c7e549ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with urllib.request.urlopen(req, timeout=600) as resp:\n",
    "        out = json.loads(resp.read().decode(\"utf-8\"))\n",
    "        response = out.get(\"response\", \"\").strip()\n",
    "except Exception as e:\n",
    "    die(f\"Ollama HTTP call failed. Is 'ollama serve' running? Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05973720-ad8a-42c9-89b2-6dd49dcf7b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Trilochanapala was a ruler of the ancient Kabul Shahi dynasty, which is believed to have ruled in the region of modern-day Afghanistan. Specifically, the Kabul Shahi kingdom was centered around the city of Kabul and the surrounding areas. So, the answer is Afghanistan.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0400a75a-21d7-42d4-ae5e-1b4fbec847ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_QUESTION = \"Given the question and your answer, how confident are you that you are correct. Answer in exactly one word from [High, Med, Low]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee92f914-ee24-4df2-84fc-8449a03d43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_prompt = f\"QUESTION:\\n{prompt}\\nYOU RESPONSE:\\n{response}\\n\\n{CONFIDENCE_QUESTION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28a88564-5185-4965-8a2c-eb4cb00485bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QUESTION:\\nTrilochanapala, last king of the Kabul Shahi dynasty, ruled in the site of which modern country?\\nYOU RESPONSE:\\nThe Trilochanapala was a ruler of the ancient Kabul Shahi dynasty, which is believed to have ruled in the region of modern-day Afghanistan. Specifically, the Kabul Shahi kingdom was centered around the city of Kabul and the surrounding areas. So, the answer is Afghanistan.\\n\\nGiven the question and your answer, how confident are you that you are correct. Answer in exactly one word from [High, Med, Low]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3aa63ea-b3a8-4b22-b575-57e413a26dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "req2 = urllib.request.Request(\n",
    "    \"http://localhost:11434/api/generate\",\n",
    "    data=json.dumps({\n",
    "        \"model\": model,\n",
    "        \"prompt\": confidence_prompt,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"seed\": seed,\n",
    "        \"stream\": False\n",
    "    }).encode(\"utf-8\"),\n",
    "    headers={\"Content-Type\": \"application/json\"}\n",
    ")\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(req2, timeout=600) as resp:\n",
    "        out = json.loads(resp.read().decode(\"utf-8\"))\n",
    "        score = out.get(\"response\", \"\").strip()\n",
    "except Exception as e:\n",
    "    die(f\"Ollama HTTP call failed. Is 'ollama serve' running? Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3287613-53bb-4cbf-86d8-819f5801829a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Med'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153bfc6-bca9-44b1-a141-15888c8899a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058230c5-eb73-492f-8a76-34aa691b4b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
